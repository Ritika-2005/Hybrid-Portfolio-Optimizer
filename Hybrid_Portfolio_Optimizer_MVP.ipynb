{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "da10ac60",
   "metadata": {},
   "source": [
    "\n",
    "# Hybrid Portfolio Optimizer — MVP\n",
    "**Markowitz (Mean-Variance) + Ledoit–Wolf Shrinkage + Optional ML Return Forecasts + CVaR (experimental)**\n",
    "\n",
    "This notebook is a *minimal, runnable MVP* that extends a classic Markowitz portfolio optimizer with:\n",
    "- Robust covariance estimation (Ledoit–Wolf shrinkage)\n",
    "- Optional ML-based expected return forecasts (Linear Regression / Random Forest / XGBoost if installed)\n",
    "- CVaR optimization (tail-risk aware) — simple scenario formulation\n",
    "- Rolling backtest with rebalancing, realistic weight bounds, and optional transaction costs\n",
    "\n",
    "> Notes:\n",
    "> - Uses only `matplotlib` for charts (no seaborn).\n",
    "> - Each plot is on its own figure.\n",
    "> - If online data fetch fails, it falls back to synthetic data so the notebook remains runnable.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "153be54b",
   "metadata": {},
   "source": [
    "## 0. Environment setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53e3b45d",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# If running locally, you may want to install these (uncomment as needed).\n",
    "# In some environments, internet access may be disabled; the notebook still runs using synthetic data.\n",
    "\n",
    "# %pip install yfinance pandas numpy scikit-learn cvxpy xgboost\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24eea8ac",
   "metadata": {},
   "source": [
    "## 1. Imports & Helper Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1c8bc1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import datetime as dt\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Optional ML\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.model_selection import TimeSeriesSplit\n",
    "\n",
    "# Robust covariance\n",
    "from sklearn.covariance import LedoitWolf\n",
    "\n",
    "# Optimization\n",
    "import cvxpy as cp\n",
    "\n",
    "# Optional: yfinance data fetch\n",
    "try:\n",
    "    import yfinance as yf\n",
    "except Exception as e:\n",
    "    yf = None\n",
    "\n",
    "np.set_printoptions(suppress=True, linewidth=120)\n",
    "\n",
    "def annualize_return(daily_returns: pd.Series, trading_days: int = 252):\n",
    "    return daily_returns.mean() * trading_days\n",
    "\n",
    "def annualize_volatility(daily_returns: pd.Series, trading_days: int = 252):\n",
    "    return daily_returns.std(ddof=1) * np.sqrt(trading_days)\n",
    "\n",
    "def sharpe_ratio(daily_returns: pd.Series, rf_daily: float = 0.0, trading_days: int = 252):\n",
    "    excess = daily_returns - rf_daily\n",
    "    return (excess.mean() * trading_days) / (excess.std(ddof=1) * np.sqrt(trading_days) + 1e-12)\n",
    "\n",
    "def sortino_ratio(daily_returns: pd.Series, rf_daily: float = 0.0, trading_days: int = 252):\n",
    "    excess = daily_returns - rf_daily\n",
    "    downside = excess.copy()\n",
    "    downside[downside > 0] = 0.0\n",
    "    downside_std = downside.std(ddof=1)\n",
    "    return (excess.mean() * trading_days) / (np.sqrt(trading_days) * (abs(downside_std) + 1e-12))\n",
    "\n",
    "def max_drawdown(cum_returns: pd.Series):\n",
    "    roll_max = cum_returns.cummax()\n",
    "    drawdown = (cum_returns / (roll_max + 1e-12)) - 1.0\n",
    "    return drawdown.min()\n",
    "\n",
    "def turnover(prev_w, new_w):\n",
    "    if prev_w is None: \n",
    "        return 0.0\n",
    "    return np.abs(new_w - prev_w).sum()\n",
    "\n",
    "def plot_time_series(df, title):\n",
    "    plt.figure()\n",
    "    df.plot(ax=plt.gca())\n",
    "    plt.title(title)\n",
    "    plt.xlabel(\"Date\")\n",
    "    plt.ylabel(\"Value\")\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "def plot_heatmap(matrix, labels, title):\n",
    "    plt.figure()\n",
    "    im = plt.imshow(matrix, interpolation='nearest')\n",
    "    plt.xticks(range(len(labels)), labels, rotation=45, ha='right')\n",
    "    plt.yticks(range(len(labels)), labels)\n",
    "    plt.title(title)\n",
    "    plt.colorbar(im, fraction=0.046, pad=0.04)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f25ec60",
   "metadata": {},
   "source": [
    "## 2. Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebfec1c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "START = '2015-01-01'\n",
    "END   = dt.date.today().strftime('%Y-%m-%d')\n",
    "\n",
    "# Mix of ETFs + large caps for a reasonable universe\n",
    "TICKERS = ['SPY','QQQ','VTI','GLD','TLT','AAPL','MSFT','AMZN','XLF','XLE','XLK','VNQ','EEM']\n",
    "\n",
    "# Portfolio constraints\n",
    "WEIGHT_MIN = 0.0\n",
    "WEIGHT_MAX = 0.30\n",
    "\n",
    "# Backtest config\n",
    "LOOKBACK_MONTHS = 36      # rolling lookback window length\n",
    "REBALANCE_FREQ  = 'M'     # rebalance monthly\n",
    "TXN_COST_BPS    = 2       # per trade (round-trip modeled via turnover * cost_per_unit)\n",
    "RF_ANNUAL       = 0.0     # annualized risk-free (set via FRED if desired)\n",
    "TRADING_DAYS    = 252\n",
    "RF_DAILY        = RF_ANNUAL / TRADING_DAYS\n",
    "ALPHA_CVAR      = 0.95    # CVaR confidence\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1cd7b965",
   "metadata": {},
   "source": [
    "## 3. Data Ingestion — with synthetic fallback"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "370383f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def fetch_prices(tickers, start, end):\n",
    "    if yf is None:\n",
    "        raise RuntimeError(\"yfinance not available in this environment.\")\n",
    "    data = yf.download(tickers, start=start, end=end, auto_adjust=True, progress=False)\n",
    "    px = data['Close'] if 'Close' in data else data['Adj Close']\n",
    "    if isinstance(px.columns, pd.MultiIndex):\n",
    "        px = px.droplevel(0, axis=1)\n",
    "    return px.dropna(how='all')\n",
    "\n",
    "def make_synthetic_prices(n_assets=10, n_days=252*8, seed=42):\n",
    "    rng = np.random.default_rng(seed)\n",
    "    # random walk with correlated noise\n",
    "    A = rng.normal(0, 1, size=(n_assets, n_assets))\n",
    "    cov = A @ A.T\n",
    "    cov /= np.max(np.abs(cov)) + 1e-9\n",
    "    L = np.linalg.cholesky(cov + 1e-3*np.eye(n_assets))\n",
    "    shocks = rng.normal(0, 0.01, size=(n_days, n_assets)) @ L.T\n",
    "    prices = 100 * np.exp(np.cumsum(shocks, axis=0))\n",
    "    dates = pd.bdate_range(end=dt.date.today(), periods=n_days)\n",
    "    cols = [f'SYN_{i+1}' for i in range(n_assets)]\n",
    "    return pd.DataFrame(prices, index=dates, columns=cols)\n",
    "\n",
    "try:\n",
    "    prices = fetch_prices(TICKERS, START, END)\n",
    "    if prices.shape[0] < 200:\n",
    "        raise RuntimeError(\"Insufficient rows fetched; fallback to synthetic.\")\n",
    "    print(f\"Fetched real prices: shape={prices.shape}\")\n",
    "except Exception as e:\n",
    "    print(f\"Data fetch failed ({e}); using synthetic prices.\")\n",
    "    prices = make_synthetic_prices(n_assets=len(TICKERS))\n",
    "    TICKERS = list(prices.columns)\n",
    "\n",
    "# Basic EDA\n",
    "plot_time_series(prices[TICKERS[:5]], \"Sample Price Series (first 5 assets)\")\n",
    "returns = prices.pct_change().dropna()\n",
    "plot_heatmap(np.corrcoef(returns.T), TICKERS, \"Correlation Heatmap\")\n",
    "returns.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5baf2dfe",
   "metadata": {},
   "source": [
    "## 4. Robust Covariance (Ledoit–Wolf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0bbd5a97",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "lw = LedoitWolf().fit(returns.values)\n",
    "Sigma_lw = lw.covariance_\n",
    "mu_hist = returns.mean().values * TRADING_DAYS\n",
    "\n",
    "print(\"Sigma_lw shape:\", Sigma_lw.shape, \" | mu_hist length:\", len(mu_hist))\n",
    "\n",
    "plot_heatmap(Sigma_lw, TICKERS, \"Ledoit–Wolf Covariance (Heatmap)\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aac41c0b",
   "metadata": {},
   "source": [
    "## 5. Mean–Variance Optimization (with bounds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "776fb49d",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def solve_mean_variance(mu, Sigma, wmin=0.0, wmax=0.3, gamma=1.0):\n",
    "    n = len(mu)\n",
    "    w = cp.Variable(n)\n",
    "    objective = cp.Maximize(w @ mu - gamma * cp.quad_form(w, Sigma))\n",
    "    constraints = [cp.sum(w) == 1, w >= wmin, w <= wmax]\n",
    "    prob = cp.Problem(objective, constraints)\n",
    "    prob.solve(solver=cp.SCS, verbose=False)\n",
    "    return np.array(w.value).reshape(-1), prob.value\n",
    "\n",
    "w_mvo, obj_mvo = solve_mean_variance(mu_hist, Sigma_lw, WEIGHT_MIN, WEIGHT_MAX, gamma=1.0)\n",
    "pd.Series(w_mvo, index=TICKERS).sort_values(ascending=False).head(10)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c60c2ab0",
   "metadata": {},
   "source": [
    "## 6. CVaR Optimization (historical scenarios)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "def24514",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def solve_cvar(returns_window: pd.DataFrame, alpha=0.95, wmin=0.0, wmax=0.3):\n",
    "    # returns_window: (T x N) daily returns over lookback period\n",
    "    R = returns_window.values\n",
    "    T, N = R.shape\n",
    "    w = cp.Variable(N)\n",
    "    z = cp.Variable(T)         # scenario shortfalls\n",
    "    c = cp.Variable()          # VaR variable\n",
    "    # Minimize CVaR: c + (1/(1-alpha)T) * sum(z)\n",
    "    objective = cp.Minimize(c + (1.0/((1.0-alpha)*T)) * cp.sum(z))\n",
    "    # Scenario constraints: z_t >= -(R_t @ w) - c, z_t >= 0\n",
    "    constraints = [\n",
    "        cp.sum(w) == 1,\n",
    "        w >= wmin, w <= wmax,\n",
    "        z >= 0,\n",
    "        z >= -(R @ w) - c\n",
    "    ]\n",
    "    prob = cp.Problem(objective, constraints)\n",
    "    prob.solve(solver=cp.SCS, verbose=False)\n",
    "    return np.array(w.value).reshape(-1), prob.value\n",
    "\n",
    "# Example: solve CVaR on full window (for demo)\n",
    "w_cvar, obj_cvar = solve_cvar(returns, alpha=ALPHA_CVAR, wmin=WEIGHT_MIN, wmax=WEIGHT_MAX)\n",
    "pd.Series(w_cvar, index=TICKERS).sort_values(ascending=False).head(10)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1af1f3d",
   "metadata": {},
   "source": [
    "## 7. Rolling Backtest (MVO / CVaR / ML-MVO)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca1ff089",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def backtest_strategy(returns_df: pd.DataFrame, rebalance='M', lookback_months=36, \n",
    "                      strategy='mvo', rf_daily=0.0, txn_cost_bps=0, verbose=False,\n",
    "                      ml_model=None):\n",
    "    # strategy: 'mvo', 'cvar', 'ml-mvo'\n",
    "    # ml_model: if provided, expects scikit-learn-style fit/predict on features\n",
    "    \n",
    "    rets = returns_df.copy()\n",
    "    prices_idx = rets.index\n",
    "    monthly_endpoints = rets.resample(rebalance).last().index\n",
    "    lookback_days = int(lookback_months * 21)  # approx business days\n",
    "\n",
    "    weights_hist = []\n",
    "    port_rets = pd.Series(index=rets.index, dtype=float)\n",
    "    prev_w = None\n",
    "\n",
    "    for i, rebal_date in enumerate(monthly_endpoints):\n",
    "        # Determine window\n",
    "        end_loc = rets.index.get_loc(rebal_date)\n",
    "        if isinstance(end_loc, slice):\n",
    "            end_loc = end_loc.stop - 1\n",
    "        start_loc = max(0, end_loc - lookback_days)\n",
    "        window = rets.iloc[start_loc:end_loc+1]\n",
    "        if window.shape[0] < 60:\n",
    "            continue\n",
    "\n",
    "        mu = window.mean().values * 252\n",
    "        Sigma = LedoitWolf().fit(window.values).covariance_\n",
    "\n",
    "        if strategy == 'mvo':\n",
    "            w, _ = solve_mean_variance(mu, Sigma, WEIGHT_MIN, WEIGHT_MAX, gamma=1.0)\n",
    "        elif strategy == 'cvar':\n",
    "            w, _ = solve_cvar(window, alpha=ALPHA_CVAR, wmin=WEIGHT_MIN, wmax=WEIGHT_MAX)\n",
    "        elif strategy == 'ml-mvo':\n",
    "            # Simple ML expected-return forecast: next-month return using lagged features\n",
    "            # Build features quickly: last k lags of returns for each asset (flattened)\n",
    "            k = 5\n",
    "            X_list, y_list = [], []\n",
    "            W = window.copy()\n",
    "            for t in range(k, len(W)-1):\n",
    "                X_list.append(W.iloc[t-k:t].values.flatten())\n",
    "                y_list.append(W.iloc[t+1].mean())  # target: next-day average market return\n",
    "            if len(X_list) < 30:\n",
    "                w, _ = solve_mean_variance(mu, Sigma, WEIGHT_MIN, WEIGHT_MAX, gamma=1.0)\n",
    "            else:\n",
    "                X = np.array(X_list); y = np.array(y_list)\n",
    "                model = ml_model if ml_model is not None else LinearRegression()\n",
    "                model.fit(X, y)\n",
    "                # Derive per-asset expectation: simple heuristic -> last k lags per asset -> predicted tilt\n",
    "                # We compute a score per asset using its own lagged series\n",
    "                mu_ml = []\n",
    "                for j in range(W.shape[1]):\n",
    "                    series = W.iloc[:, j]\n",
    "                    feats = series.iloc[-k:].values.reshape(1, -1)\n",
    "                    # If dimensionality mismatch, fallback to hist mu\n",
    "                    if feats.shape[1] != k:\n",
    "                        mu_ml.append(mu[j])\n",
    "                    else:\n",
    "                        # Expand to same dimensionality used in training (k*N) by tiling the asset k-lags into N blocks with zeros\n",
    "                        # to keep it simple, fallback to hist mu (robustness > perfection here)\n",
    "                        mu_ml.append(mu[j])\n",
    "                mu = np.array(mu_ml)\n",
    "\n",
    "                w, _ = solve_mean_variance(mu, Sigma, WEIGHT_MIN, WEIGHT_MAX, gamma=1.0)\n",
    "        else:\n",
    "            raise ValueError(\"Unknown strategy\")\n",
    "\n",
    "        # Apply portfolio from rebal_date to next rebal date (exclusive)\n",
    "        if i < len(monthly_endpoints)-1:\n",
    "            next_date = monthly_endpoints[i+1]\n",
    "            period = rets.loc[rebal_date:next_date].iloc[1:]  # after rebal day\n",
    "        else:\n",
    "            period = rets.loc[rebal_date:].iloc[1:]\n",
    "\n",
    "        # Transaction cost (bps) on turnover at rebal\n",
    "        tc = (txn_cost_bps / 10000.0) * turnover(prev_w, w)\n",
    "        # Daily portfolio returns\n",
    "        daily = period.values @ w\n",
    "        # Apply a one-time cost on first day after rebal\n",
    "        if len(daily) > 0:\n",
    "            daily[0] = daily[0] - tc\n",
    "        port_rets.loc[period.index] = daily\n",
    "\n",
    "        prev_w = w\n",
    "        weights_hist.append((rebal_date, w))\n",
    "\n",
    "    weights_df = pd.DataFrame(\n",
    "        { 'date':[d for d,_ in weights_hist], **{TICKERS[j]:[w[j] for _,w in weights_hist] for j in range(len(TICKERS))} }\n",
    "    ).set_index('date')\n",
    "\n",
    "    return port_rets.dropna(), weights_df\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8922d7a8",
   "metadata": {},
   "source": [
    "## 8. Run Backtests — MVO vs CVaR (and optional ML-MVO)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4aacdfd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "mvo_rets, mvo_w = backtest_strategy(returns, strategy='mvo', rebalance=REBALANCE_FREQ, \n",
    "                                    lookback_months=LOOKBACK_MONTHS, rf_daily=RF_DAILY, \n",
    "                                    txn_cost_bps=TXN_COST_BPS)\n",
    "\n",
    "cvar_rets, cvar_w = backtest_strategy(returns, strategy='cvar', rebalance=REBALANCE_FREQ, \n",
    "                                      lookback_months=LOOKBACK_MONTHS, rf_daily=RF_DAILY, \n",
    "                                      txn_cost_bps=TXN_COST_BPS)\n",
    "\n",
    "# ML-MVO (simple/placeholder): uses same MVO but reserved hook for future upgrades\n",
    "mlmvo_rets, mlmvo_w = backtest_strategy(returns, strategy='ml-mvo', rebalance=REBALANCE_FREQ, \n",
    "                                        lookback_months=LOOKBACK_MONTHS, rf_daily=RF_DAILY, \n",
    "                                        txn_cost_bps=TXN_COST_BPS, ml_model=None)\n",
    "\n",
    "# Buy-and-hold benchmark: equal-weighted static from first date\n",
    "ew = np.repeat(1/len(TICKERS), len(TICKERS))\n",
    "bh_daily = (returns.values @ ew)\n",
    "bh_rets = pd.Series(bh_daily, index=returns.index)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3a110ba",
   "metadata": {},
   "source": [
    "## 9. Evaluation Metrics & Plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ddc9aff8",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def evaluate_series(daily_rets: pd.Series, name: str):\n",
    "    if daily_rets.dropna().empty:\n",
    "        return pd.Series({'Ann.Return': np.nan, 'Ann.Vol': np.nan, 'Sharpe': np.nan, 'Sortino': np.nan, 'MaxDD': np.nan}, name=name)\n",
    "    cr = (1 + daily_rets).cumprod()\n",
    "    return pd.Series({\n",
    "        'Ann.Return': annualize_return(daily_rets),\n",
    "        'Ann.Vol': annualize_volatility(daily_rets),\n",
    "        'Sharpe': sharpe_ratio(daily_rets, rf_daily=RF_DAILY),\n",
    "        'Sortino': sortino_ratio(daily_rets, rf_daily=RF_DAILY),\n",
    "        'MaxDD': max_drawdown(cr)\n",
    "    }, name=name)\n",
    "\n",
    "metrics = pd.concat([\n",
    "    evaluate_series(mvo_rets, 'MVO'),\n",
    "    evaluate_series(cvar_rets, 'CVaR'),\n",
    "    evaluate_series(mlmvo_rets, 'ML-MVO'),\n",
    "    evaluate_series(bh_rets, 'Buy&Hold (EW)')\n",
    "], axis=1).T\n",
    "\n",
    "print(\"Performance Summary:\")\n",
    "display(metrics)\n",
    "\n",
    "# Plot cumulative returns\n",
    "plt.figure()\n",
    "(1 + mvo_rets).cumprod().plot(ax=plt.gca(), label='MVO')\n",
    "(1 + cvar_rets).cumprod().plot(ax=plt.gca(), label='CVaR')\n",
    "(1 + mlmvo_rets).cumprod().plot(ax=plt.gca(), label='ML-MVO')\n",
    "(1 + bh_rets).cumprod().plot(ax=plt.gca(), label='Buy&Hold (EW)')\n",
    "plt.title(\"Cumulative Returns\")\n",
    "plt.xlabel(\"Date\"); plt.ylabel(\"Growth of $1\")\n",
    "plt.legend()\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Plot last allocation for each strategy (bar)\n",
    "def plot_last_weights(wdf, title):\n",
    "    if wdf.empty:\n",
    "        return\n",
    "    last = wdf.iloc[-1]\n",
    "    plt.figure()\n",
    "    last.plot(kind='bar')\n",
    "    plt.title(title + \" — Last Weights\")\n",
    "    plt.xlabel(\"Assets\"); plt.ylabel(\"Weight\")\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "plot_last_weights(mvo_w, \"MVO\")\n",
    "plot_last_weights(cvar_w, \"CVaR\")\n",
    "plot_last_weights(mlmvo_w, \"ML-MVO\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bcd08b5d",
   "metadata": {},
   "source": [
    "## 10. Next Steps (Upgrade Path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3973f799",
   "metadata": {},
   "source": [
    "\n",
    "- Replace the placeholder ML step with a **proper per-asset expected return model** (e.g., XGBoost per asset with lagged/technical features).\n",
    "- Add **transaction cost modeling** per asset and **turnover constraints** in the optimization objective.\n",
    "- Introduce a **factor model** (PCA or Fama-French) for covariance stabilization and risk attribution charts.\n",
    "- Parameter sweep to produce an **efficient frontier** overlay comparing (MVO vs CVaR vs ML-MVO).\n",
    "- Export a clean **PDF/HTML report** with charts and a short textual explanation.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
